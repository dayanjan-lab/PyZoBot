{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PyZoBot: A Platform for Conversational Information Extraction and Synthesis from Curated Zotero Reference Libraries through Advanced Retrieval-Augmented Generation.\n",
    "\n",
    "## File: PyZoBot.ipynb\n",
    "\n",
    "Description: This module serves as the main entry point for the PyZoBot application. It integrates Zotero's reference management capabilities with OpenAI's advanced language models to streamline and enhance the process of scientific literature review.\n",
    "\n",
    "## Copyright (2024) Suad Alshammari, Lama Basalelah, Walaa Abu Rukbah, Ali Alsuhibani, Dayanjan S. Wijesinghe\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
    "\n",
    "https://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dSsFYMXQM7mq"
   },
   "outputs": [],
   "source": [
    "#Dependencies:\n",
    "!pip install pyzotero -q\n",
    "!pip install pandas -q\n",
    "!pip install requests -q\n",
    "!pip install openai -q\n",
    "!pip install pinecone-client -q\n",
    "!pip install langchain -q\n",
    "!pip install unstructured -q\n",
    "!pip install \"unstructured[pdf]\" -q\n",
    "!pip install tiktoken -q\n",
    "!pip install fitz -q\n",
    "!pip install PyPDF2 -q\n",
    "!pip install PyMuPDF -q\n",
    "!pip install llama_index --q\n",
    "#!pip install chromadb --q\n",
    "!pip install chromadb==0.4.15 -q"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import shutil\n",
    "\n",
    "folder_path = \"/content/pdfs_output\"  # Replace with your folder path\n",
    "\n",
    "# Check if the folder exists\n",
    "if shutil.os.path.exists(folder_path):\n",
    "    # If it exists, delete it\n",
    "    shutil.rmtree(folder_path)\n",
    "    print(f\"The folder at {folder_path} has been deleted.\")\n",
    "else:\n",
    "    print(f\"The folder at {folder_path} does not exist.\")"
   ],
   "metadata": {
    "id": "oE98pQ3h5UYg"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key:\")\n",
    "\n",
    "zotero_api_key= getpass(\"Enter your Zotero API key:\")\n",
    "library_type= getpass(\"Enter your Zotero library type (in small letters write group or user):\")\n",
    "library_id= getpass(\"Enter your Zotero library id:\")"
   ],
   "metadata": {
    "id": "NyG8DjCZNEuE",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b0817cf9-3fce-463e-832a-2bb9672bf1a9"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import time\n",
    "# %%time\n",
    "import os\n",
    "import openai\n",
    "import pinecone\n",
    "import langchain\n",
    "import tqdm\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from tqdm.autonotebook import tqdm"
   ],
   "metadata": {
    "id": "DId2di-_NXDU"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from pyzotero import zotero\n",
    "zot = zotero.Zotero(library_id=library_id, library_type=library_type, api_key= zotero_api_key)\n",
    "items = zot.everything(zot.top())"
   ],
   "metadata": {
    "id": "jhVnVCg-Nb-x"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "df=  pd.json_normalize(items)"
   ],
   "metadata": {
    "id": "TwG1R-YNNf5R"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# ## Activate this chunk if you want to interact with a collection (pass the collection ID ):\n",
    "\n",
    "# collection_ID = '4PBTYQIY'\n",
    "\n",
    "# # Filter rows based on the presence of the collection_ID\n",
    "# df = df[df['data.collections'].apply(lambda x: collection_ID in x)]"
   ],
   "metadata": {
    "id": "gYP9HMu_YALL"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df1 = df[df['meta.numChildren'] == 0]\n",
    "df2 = df[df['meta.numChildren'] != 0]"
   ],
   "metadata": {
    "id": "B4JfT_gxNiC2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df2['links.self.href'] = df2['links.self.href'].astype(str)+ '/children'"
   ],
   "metadata": {
    "id": "q_zjuvDaNkdT",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "20dd1985-ac75-4b23-ce71-a496bc42b1a4"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "frames = [df1, df2]\n",
    "\n",
    "df3 = pd.concat(frames)"
   ],
   "metadata": {
    "id": "MzIuT4UhNnwM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df4=df3\n",
    "import requests\n",
    "def fetch_url_content_as_json(url):\n",
    "    try:\n",
    "        headers = {\n",
    "            'Zotero-API-Key': f'{zotero_api_key}'  # Adjust the header based on your API's requirements\n",
    "        }\n",
    "        response = requests.get(url, headers=headers)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            return response.json()  # Parse JSON response\n",
    "        else:\n",
    "            return {\"error\": f\"Error: {response.status_code}\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Error: {str(e)}\"}\n",
    "\n",
    "# Apply the function to fetch JSON content\n",
    "df4['JSONContent'] = df4['links.self.href'].apply(fetch_url_content_as_json)"
   ],
   "metadata": {
    "id": "JFJWYxE-Nx_J"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def flatten_json(nested_json: dict, exclude: list=['']) -> dict:\n",
    "    \"\"\"\n",
    "    Flatten a list of nested dicts.\n",
    "    \"\"\"\n",
    "    out = dict()\n",
    "    def flatten(x: (list, dict, str), name: str='', exclude=exclude):\n",
    "        if type(x) is dict:\n",
    "            for a in x:\n",
    "                if a not in exclude:\n",
    "                    flatten(x[a], f'{name}{a}.')\n",
    "        elif type(x) is list:\n",
    "            i = 0\n",
    "            for a in x:\n",
    "                flatten(a, f'{name}{i}.')\n",
    "                i += 1\n",
    "        else:\n",
    "            out[name[:-1]] = x\n",
    "\n",
    "    flatten(nested_json)\n",
    "    return out"
   ],
   "metadata": {
    "id": "fsDKBOCsN2A5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_source2 = pd.DataFrame([flatten_json(x) for x in df4['JSONContent']])"
   ],
   "metadata": {
    "id": "1J3sR2LwN6Jz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import re\n",
    "df9= df_source2\n",
    "cols_to_join = [col for col in df9.columns if col.endswith('.enclosure.href')]\n",
    "df9['enclosure.href'] = df9[cols_to_join].apply(lambda x: '##'.join(x.values.astype(str)), axis=1)"
   ],
   "metadata": {
    "id": "Wuogom2rN8h6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df10= df9\n",
    "cols_to_join = [col for col in df10.columns if col.endswith('.enclosure.title')]\n",
    "df10['enclosure.title'] = df10[cols_to_join].apply(lambda x: '##'.join(x.values.astype(str)), axis=1)"
   ],
   "metadata": {
    "id": "Zvz8Jc_wOA75"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df11= df10[['enclosure.title', 'enclosure.href']]"
   ],
   "metadata": {
    "id": "KngIitZOOCPJ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Split the rows at '##' and create a list of new rows\n",
    "df12=df11\n",
    "new_df = df12['enclosure.title'].str.split('##', expand=True).stack().reset_index(level=1, drop=True).to_frame('enclosure.title')\n",
    "# new_df\n",
    "df12 = df12.drop('enclosure.title', axis=1).join(new_df)\n",
    "# df12"
   ],
   "metadata": {
    "id": "PL1nj0j4OEga"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Split the rows at '##' and create a list of new rows\n",
    "df13=df12\n",
    "new_df2 = df13['enclosure.href'].str.split('##', expand=True).stack().reset_index(level=1, drop=True).to_frame('enclosure.href')\n",
    "\n",
    "# new_df\n",
    "\n",
    "df13 = df13.drop('enclosure.href', axis=1).join(new_df2)\n",
    "df13.dropna(inplace=True)\n",
    "# df13"
   ],
   "metadata": {
    "id": "jddFa8GpOJk7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df15= df13\n",
    "df15 = df15.replace('nan', pd.NA)\n",
    "df15= df15.dropna()\n",
    "# df15"
   ],
   "metadata": {
    "id": "VN5ixNbAOM2V"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df15['PDF_Names'] = df15['enclosure.title']\n",
    "df15= df15[['PDF_Names', 'enclosure.href']]\n"
   ],
   "metadata": {
    "id": "aPEpiLrQOPu7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df16= df15.drop_duplicates(keep='first')\n",
    "# df16"
   ],
   "metadata": {
    "id": "kzxiHizeOTGD"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Filter rows where the \"PDF_Names\" column ends with \".pdf\"\n",
    "df17 = df16[df16['PDF_Names'].str.endswith('.pdf')]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "#df17"
   ],
   "metadata": {
    "id": "4lHwJI0AOWiz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Create empty folder to store the pdfs\n",
    "\n",
    "import os\n",
    "\n",
    "# Specify the folder name you want to create\n",
    "folder_name = 'pdfs_output'\n",
    "\n",
    "# Path to the content directory in Google Colab\n",
    "content_path = '/content'\n",
    "\n",
    "# Full path to the new folder\n",
    "folder_path = os.path.join(content_path, folder_name)\n",
    "\n",
    "# Check if the folder already exists\n",
    "if not os.path.exists(folder_path):\n",
    "    # Create the folder\n",
    "    os.makedirs(folder_path)\n",
    "    print(f\"Folder '{folder_name}' created successfully at {folder_path}\")\n",
    "else:\n",
    "    print(f\"Folder '{folder_name}' already exists at {folder_path}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wgjpn-fYOYne",
    "outputId": "28e7a313-ad48-4a40-bbca-825175d3d946"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Folder 'pdfs_output' created successfully at /content/pdfs_output\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df20=df17\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "# Define your output folder\n",
    "output_folder = \"/content/pdfs_output\"\n",
    "\n",
    "\n",
    "headers = {'Zotero-API-Key': f'{zotero_api_key}'}\n",
    "\n",
    "# Iterate through the dataframe\n",
    "for index, row in df20.iterrows():\n",
    "    api_url = row['enclosure.href']\n",
    "    pdf_filename = row['PDF_Names']\n",
    "\n",
    "    # Make an HTTP GET request for each URL\n",
    "    response = requests.get(api_url, headers=headers)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        binary_content = response.content\n",
    "        content_type = response.headers.get(\"Content-Type\")\n",
    "\n",
    "        # Check if the content type is 'pdf/application'\n",
    "        if content_type == 'application/pdf':\n",
    "            pdf_filename = row['PDF_Names']\n",
    "            pdf_filepath = os.path.join(output_folder, pdf_filename)\n",
    "\n",
    "            # Save the PDF to the specified folder\n",
    "            with open(pdf_filepath, 'wb') as pdf_file:\n",
    "                pdf_file.write(binary_content)\n",
    "\n",
    "            print(f\"Saved PDF: {pdf_filename}\")\n",
    "        else:\n",
    "            print(f\"Skipped non-PDF content for URL: {api_url}\")\n",
    "    else:\n",
    "        print(f\"Failed to fetch data from the API for URL: {api_url}\")\n",
    "\n",
    "print(\"All PDFs processed.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1mWvfOnROb8s",
    "outputId": "b2e162d7-bb4f-428a-e226-7885df5fee84"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import time\n",
    "# %%time\n",
    "import os\n",
    "import openai\n",
    "import pinecone\n",
    "import langchain\n",
    "import tqdm\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from tqdm.autonotebook import tqdm"
   ],
   "metadata": {
    "id": "X94COPekOgFj"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install llama-index-core\n",
    "!pip install llama-index-llms-openai\n",
    "!pip install llama-index-llms-replicate\n",
    "!pip install llama-index-embeddings-huggingface"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bFKaREJuEZHn",
    "outputId": "d95c8acf-6528-4cd8-8827-477d1a3ef5fb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install -U llama-index llama-index-core"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4TmOm22rfcsa",
    "outputId": "300a0016-d2ab-4972-891a-220d016335f7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from llama_index.core import download_loader"
   ],
   "metadata": {
    "id": "cdSO8Gazfpd2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#! pip install llama_index --q\n",
    "pdfs_dir = output_folder\n",
    "pdf_names = os.listdir(pdfs_dir)\n",
    "pdf_paths = [os.path.join(pdfs_dir, pdf_name) for pdf_name in pdf_names]\n",
    "\n",
    "# PDF loader from LLama index : https://llamahub.ai/l/file-pdf\n",
    "from pathlib import Path\n",
    "from llama_index.core import download_loader\n",
    "\n",
    "PyMuPDFReader = download_loader(\"PyMuPDFReader\")\n",
    "\n",
    "loader = PyMuPDFReader()\n",
    "\n",
    "\n",
    "all_documents = []\n",
    "\n",
    "# Process each PDF file\n",
    "for pdf_file in pdf_paths:\n",
    "    print(f\"Processing file: {pdf_file}\")\n",
    "    documents = loader.load_data(file_path=pdf_file, metadata=True)\n",
    "    # Add your processing logic here, using the 'documents' variable\n",
    "    print(f\"Number of documents in {pdf_file}: {len(documents)}\")\n",
    "\n",
    "    # Extend the list with documents from the current file\n",
    "    all_documents.extend(documents)\n",
    "\n",
    "# You can add additional processing or analysis outside the loop if needed\n",
    "\n",
    "# Print the total number of documents\n",
    "print(f\"Total number of documents: {len(all_documents)}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7zd4KUMkOkir",
    "outputId": "646c4315-f5f9-4fa5-c389-64154ff37e30"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import langchain\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")"
   ],
   "metadata": {
    "id": "NH8MKEGYQDnE",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4b6314d2-8f9e-4f21-ef54-ea8a70d02793"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "# Assuming you have the 'all_documents' list of objects with 'get_text()' and 'metadata' attributes\n",
    "\n",
    "chunk_size_limit = 500\n",
    "max_chunk_overlap = 200\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size_limit,\n",
    "    chunk_overlap=max_chunk_overlap\n",
    ")\n",
    "# Assuming you have a Document class with 'page_content' and 'metadata' attributes\n",
    "class langchainschemadocumentDocument:\n",
    "    def __init__(self, page_content, metadata):\n",
    "        self.page_content = page_content\n",
    "        self.metadata = metadata\n",
    "\n",
    "# Initialize an empty list to store the split documents\n",
    "split_docs = []\n",
    "\n",
    "# Iterate through the documents and split each one\n",
    "for document in all_documents:\n",
    "    text = document.get_text()  # Replace with the actual method for getting text\n",
    "    source = document.metadata['file_path'].split('/')[-1]  # Extract the file name\n",
    "\n",
    "    # Split the document using the text splitter\n",
    "    chunks = text_splitter.split_text(text)\n",
    "\n",
    "    # Create Document instances for each chunk\n",
    "    for chunk in chunks:\n",
    "        # Use metadata as a dictionary with a key-value pair for the file name\n",
    "        metadata = {'source': source}\n",
    "        chunk_instance = Document(page_content=chunk, metadata=metadata)\n",
    "        split_docs.append(chunk_instance)\n",
    "        ids = [str(i) for i in range(1, len(split_docs) + 1)]"
   ],
   "metadata": {
    "id": "GioUdGITxK2w"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Try to delete the collection if it exists\n",
    "try:\n",
    "    db.delete_collection()\n",
    "except Exception as e:\n",
    "    pass\n",
    "\n",
    "# Now, create the Chroma vector store\n",
    "db = Chroma.from_documents(split_docs, embeddings, ids=ids)"
   ],
   "metadata": {
    "id": "nQfGq709zr30"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "system_template=\"\"\"Answer the user query using the relevant content provided in this prompt.\n",
    "If you don't know the answer, just say that \"I don't know\", don't try to make up an answer.\\n\n",
    "Take your time and provide as much information as you can in the answer.\\n\n",
    "For each sentence you write provide in-text citation, e.g., [1].\\n start with number [1] everytime you generate an answer\\n\n",
    "If the sentence that you write has multiple citation provide them all, e.g., [1],[2],[3]... .\\n\n",
    "By the end of the answer provide References section as Markdown (###References) including the number and the file name\\n\n",
    "e.g., [1] Author et al. - YEAR- file name.pdf\\n\n",
    "Don't combine the References and write each one in new line.\\n\n",
    "\n",
    "----------------\n",
    "{summaries}\"\"\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessagePromptTemplate.from_template(system_template),\n",
    "    HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "]\n",
    "prompt = ChatPromptTemplate.from_messages(messages)"
   ],
   "metadata": {
    "id": "5dxf6LPzW05X"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "\n",
    "chain_type_kwargs = {\"prompt\": prompt}\n",
    "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0, max_tokens=4000)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q9gZpaqncm3j",
    "outputId": "1dc4083f-368c-4f6a-b3c8-e4f9f6dfca6c"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "### for more information about the as.retriever() :: https://python.langchain.com/docs/use_cases/question_answering/how_to/vector_db_qa ::\n",
    "# %%time\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(base_compressor=compressor, base_retriever=db.as_retriever(search_type=\"mmr\", search_kwargs={'k': 30, 'lambda_mult': 0.25}))\n"
   ],
   "metadata": {
    "id": "oulAUFBbcsUC"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "sample_question = \"write the question here\""
   ],
   "metadata": {
    "id": "erNIICpqcuyS"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=compression_retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs=chain_type_kwargs,\n",
    "    verbose=True\n",
    ")"
   ],
   "metadata": {
    "id": "_ouE9wAdcv6m"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from IPython.display import display, Markdown\n",
    "def print_result(result):\n",
    "  output_text = f\"\"\"### Question:\n",
    "  {sample_question}\n",
    "  ### Answer:\n",
    "  {result['answer']}\n",
    "  ### Sources:\n",
    "  {result['source_documents']}\n",
    "  ### All relevant sources:\n",
    "  {' '.join(list(set([doc.metadata['source'] for doc in result['source_documents']])))}\n",
    "  \"\"\"\n",
    "  display(Markdown(output_text))"
   ],
   "metadata": {
    "id": "erayDMNcdEh5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "result = chain(sample_question)\n",
    "print_result(result)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "id": "KLU7gcdNdHTh",
    "outputId": "e115dedf-ec7e-47a5-de42-02c162bb264a"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
